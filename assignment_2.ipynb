{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Spam and Ham data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import email\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(fn):\n",
    "    dataset = list()\n",
    "    with tarfile.open(fn) as tf:\n",
    "        for i in tf:\n",
    "            if i.isfile():\n",
    "                with tf.extractfile(i) as f:\n",
    "                    b = f.read()\n",
    "                    # Parse the email to get the charset\n",
    "                    try:\n",
    "                        msg = email.message_from_bytes(b)\n",
    "                        charset = msg.get_content_charset()\n",
    "                        if not charset:\n",
    "                            charset = 'iso-8859-1'  # Default if charset not specified\n",
    "                        s = b.decode(charset, errors='replace')\n",
    "                    except:\n",
    "                        s = b.decode('iso-8859-1', errors='replace')\n",
    "                    dataset.append(s)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(email_list, label):\n",
    "    df = pd.DataFrame(email_list, columns=['email'])\n",
    "    df['label'] = label\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'easy_ham': read_data('20021010_easy_ham.tar.bz2'),\n",
    "    'hard_ham': read_data('20021010_hard_ham.tar.bz2'),\n",
    "    'spam': read_data('20021010_spam.tar.bz2')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for each category with specific labels\n",
    "df_easy_ham = create_dataframe(data['easy_ham'], 'easy_ham')\n",
    "df_hard_ham = create_dataframe(data['hard_ham'], 'hard_ham')\n",
    "df_spam = create_dataframe(data['spam'], 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_easy_ham.to_csv(\"easy_ham_content.csv\")\n",
    "df_hard_ham.to_csv(\"hard_ham_content.csv\")\n",
    "df_spam.to_csv(\"spam_content.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upon examining the datasets, spam emails are distinguishable from ham by their promotional content, unsolicited offers, and persuasive language aimed at eliciting a response, such as advertising hosting services at unusually low prices. They often contain multiple links, unsubscribe options, and specific keywords like \"hosting,\" \"business,\" and \"discount.\" In contrast, easy ham emails are clearly legitimate communications with personal or organizational content, proper formatting, and relevant headers, making them easily identifiable as non-spam. Hard ham emails, while still legitimate, may resemble spam more closely due to their automated or bulk nature, such as newsletters or subscription confirmations. These hard ham emails often include numerous links and standardized templates, which can make them harder to differentiate from spam without closer inspection.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_eh, X_test_eh, y_train_eh, y_test_eh = train_test_split(\n",
    "    df_easy_ham['email'],\n",
    "    df_easy_ham['label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train_hh, X_test_hh, y_train_hh, y_test_hh = train_test_split(\n",
    "    df_hard_ham['email'],\n",
    "    df_hard_ham['label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train_spam, X_test_spam, y_train_spam, y_test_spam = train_test_split(\n",
    "    df_spam['email'],\n",
    "    df_spam['label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for training sets\n",
    "df_train_spam = pd.DataFrame({'email': X_train_spam, 'label': y_train_spam})\n",
    "df_train_easy_ham = pd.DataFrame({'email': X_train_eh, 'label': y_train_eh})\n",
    "df_train_hard_ham = pd.DataFrame({'email': X_train_hh, 'label': y_train_hh})\n",
    "\n",
    "# Create DataFrames for testing sets\n",
    "df_test_spam = pd.DataFrame({'email': X_test_spam, 'label': y_test_spam})\n",
    "df_test_easy_ham = pd.DataFrame({'email': X_test_eh, 'label': y_test_eh})\n",
    "df_test_hard_ham = pd.DataFrame({'email': X_test_hh, 'label': y_test_hh})\n",
    "\n",
    "# Training splits\n",
    "df_train_spam.to_csv(\"train_spam.csv\", index=False)\n",
    "df_train_easy_ham.to_csv(\"train_easy_ham.csv\", index=False)\n",
    "df_train_hard_ham.to_csv(\"train_hard_ham.csv\", index=False)\n",
    "\n",
    "# Testing splits\n",
    "df_test_spam.to_csv(\"test_spam.csv\", index=False)\n",
    "df_test_easy_ham.to_csv(\"test_easy_ham.csv\", index=False)\n",
    "df_test_hard_ham.to_csv(\"test_hard_ham.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training data for easy_ham vs spam\n",
    "X_train_eh_spam = pd.concat([X_train_spam, X_train_eh], ignore_index=True)\n",
    "y_train_eh_spam = pd.concat([y_train_spam, y_train_eh], ignore_index=True)\n",
    "\n",
    "# Combine training data for hard_ham vs spam\n",
    "X_train_hh_spam = pd.concat([X_train_spam, X_train_hh], ignore_index=True)\n",
    "y_train_hh_spam = pd.concat([y_train_spam, y_train_hh], ignore_index=True)\n",
    "\n",
    "# Initialize separate CountVectorizers\n",
    "count_eh = CountVectorizer()\n",
    "count_hh = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_eh_spam_counts = count_eh.fit_transform(X_train_eh_spam)\n",
    "X_train_hh_spam_counts = count_hh.fit_transform(X_train_hh_spam)\n",
    "\n",
    "# Combine test data for easy_ham vs spam\n",
    "X_test_eh_spam = pd.concat([X_test_spam, X_test_eh], ignore_index=True)\n",
    "y_test_eh_spam = pd.concat([y_test_spam, y_test_eh], ignore_index=True)\n",
    "\n",
    "# Combine test data for hard_ham vs spam\n",
    "X_test_hh_spam = pd.concat([X_test_spam, X_test_hh], ignore_index=True)\n",
    "y_test_hh_spam = pd.concat([y_test_spam, y_test_hh], ignore_index=True)\n",
    "\n",
    "# Transform the test data using the fitted vectorizers\n",
    "X_test_eh_spam_counts = count_eh.transform(X_test_eh_spam)\n",
    "X_test_hh_spam_counts = count_hh.transform(X_test_hh_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes (Easy Ham):\n",
      "Accuracy: 0.9624\n",
      "Precision: 0.9875\n",
      "Recall: 0.7822\n",
      "\n",
      "Bernoulli Naive Bayes (Easy Ham):\n",
      "Accuracy: 0.9020\n",
      "Precision: 0.9767\n",
      "Recall: 0.4158\n"
     ]
    }
   ],
   "source": [
    "# Initialize the classifiers\n",
    "multinomial_nb = MultinomialNB()\n",
    "bernoulli_nb = BernoulliNB()\n",
    "\n",
    "# Train Multinomial Naive Bayes\n",
    "multinomial_nb.fit(X_train_eh_spam_counts, y_train_eh_spam)\n",
    "\n",
    "# Train Bernoulli Naive Bayes\n",
    "bernoulli_nb.fit(X_train_eh_spam_counts, y_train_eh_spam)\n",
    "\n",
    "# Predict on the test set using Multinomial Naive Bayes\n",
    "y_pred_multinomial = multinomial_nb.predict(X_test_eh_spam_counts)\n",
    "\n",
    "# Predict on the test set using Bernoulli Naive Bayes\n",
    "y_pred_bernoulli = bernoulli_nb.predict(X_test_eh_spam_counts)\n",
    "\n",
    "# Calculate metrics for Multinomial Naive Bayes\n",
    "accuracy_multinomial = accuracy_score(y_test_eh_spam, y_pred_multinomial)\n",
    "precision_multinomial = precision_score(y_test_eh_spam, y_pred_multinomial, pos_label='spam')\n",
    "recall_multinomial = recall_score(y_test_eh_spam, y_pred_multinomial, pos_label='spam')\n",
    "\n",
    "# Calculate metrics for Bernoulli Naive Bayes\n",
    "accuracy_bernoulli = accuracy_score(y_test_eh_spam, y_pred_bernoulli)\n",
    "precision_bernoulli = precision_score(y_test_eh_spam, y_pred_bernoulli, pos_label='spam')\n",
    "recall_bernoulli = recall_score(y_test_eh_spam, y_pred_bernoulli, pos_label='spam')\n",
    "\n",
    "# Generate confusion matrices\n",
    "conf_matrix_multinomial = confusion_matrix(y_test_eh_spam, y_pred_multinomial, labels=['spam', 'easy_ham'])\n",
    "conf_matrix_bernoulli = confusion_matrix(y_test_eh_spam, y_pred_bernoulli, labels=['spam', 'easy_ham'])\n",
    "\n",
    "def plot_confusion_matrix_with_margins(cm, classifier_name):\n",
    "    # Calculate marginal sums\n",
    "    row_sums = cm.sum(axis=1)\n",
    "    col_sums = cm.sum(axis=0)\n",
    "    total = cm.sum()\n",
    "    \n",
    "    # Create a new figure with extra space for margins\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Create a heatmap\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax,\n",
    "                xticklabels=['Predicted Spam', 'Predicted Easy Ham'],\n",
    "                yticklabels=['Actual Spam', 'Actual Easy Ham'])\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_title(f'Confusion Matrix - {classifier_name}', pad=20)\n",
    "    \n",
    "    # Adjust the plot to make space for marginal sums\n",
    "    plt.subplots_adjust(left=0.2, bottom=0.2)\n",
    "    \n",
    "    # Get the axes limits\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    # Add row sums to the right of each row\n",
    "    for i, row_sum in enumerate(row_sums):\n",
    "        ax.text(xlim[1] + 0.1, i + 0.5, f'{row_sum}', va='center', ha='left', fontsize=12)\n",
    "    \n",
    "    # Add column sums below each column\n",
    "    for i, col_sum in enumerate(col_sums):\n",
    "        ax.text(i + 0.5, ylim[0] + 0.3, f'{col_sum}', va='bottom', ha='center', fontsize=12)\n",
    "    \n",
    "    # Add total sum at the bottom-right corner\n",
    "    ax.text(xlim[1] + 0.1, ylim[0] + 0.3, f'{total}', va='bottom', ha='left', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Adjust axes limits to accommodate marginal sums\n",
    "    ax.set_xlim(xlim[0], xlim[1] + 1)\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    \n",
    "    # Remove any residual whitespace\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the confusion matrix as a PDF\n",
    "    plt.savefig(f'confusion_matrix_{classifier_name}.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Plot and save confusion matrices without legends and with marginal sums\n",
    "plot_confusion_matrix_with_margins(conf_matrix_multinomial, 'MultinomialNB_EasyHam')\n",
    "plot_confusion_matrix_with_margins(conf_matrix_bernoulli, 'BernoulliNB_EasyHam')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Multinomial Naive Bayes (Easy Ham):\")\n",
    "print(f\"Accuracy: {accuracy_multinomial:.4f}\")\n",
    "print(f\"Precision: {precision_multinomial:.4f}\")\n",
    "print(f\"Recall: {recall_multinomial:.4f}\\n\")\n",
    "\n",
    "print(\"Bernoulli Naive Bayes (Easy Ham):\")\n",
    "print(f\"Accuracy: {accuracy_bernoulli:.4f}\")\n",
    "print(f\"Precision: {precision_bernoulli:.4f}\")\n",
    "print(f\"Recall: {recall_bernoulli:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes (Hard Ham):\n",
      "Accuracy: 0.9735\n",
      "Precision: 0.9619\n",
      "Recall: 1.0000\n",
      "\n",
      "Bernoulli Naive Bayes (Hard Ham):\n",
      "Accuracy: 0.9007\n",
      "Precision: 0.8839\n",
      "Recall: 0.9802\n"
     ]
    }
   ],
   "source": [
    "# Initialize the classifiers\n",
    "multinomial_nb_hh = MultinomialNB()\n",
    "bernoulli_nb_hh = BernoulliNB()\n",
    "\n",
    "# Train Multinomial Naive Bayes on Hard Ham vs Spam\n",
    "multinomial_nb_hh.fit(X_train_hh_spam_counts, y_train_hh_spam)\n",
    "\n",
    "# Train Bernoulli Naive Bayes on Hard Ham vs Spam\n",
    "bernoulli_nb_hh.fit(X_train_hh_spam_counts, y_train_hh_spam)\n",
    "\n",
    "# Predict on the test set using Multinomial Naive Bayes\n",
    "y_pred_multinomial_hh = multinomial_nb_hh.predict(X_test_hh_spam_counts)\n",
    "\n",
    "# Predict on the test set using Bernoulli Naive Bayes\n",
    "y_pred_bernoulli_hh = bernoulli_nb_hh.predict(X_test_hh_spam_counts)\n",
    "\n",
    "# Calculate metrics for Multinomial Naive Bayes\n",
    "accuracy_multinomial_hh = accuracy_score(y_test_hh_spam, y_pred_multinomial_hh)\n",
    "precision_multinomial_hh = precision_score(y_test_hh_spam, y_pred_multinomial_hh, pos_label='spam')\n",
    "recall_multinomial_hh = recall_score(y_test_hh_spam, y_pred_multinomial_hh, pos_label='spam')\n",
    "\n",
    "# Calculate metrics for Bernoulli Naive Bayes\n",
    "accuracy_bernoulli_hh = accuracy_score(y_test_hh_spam, y_pred_bernoulli_hh)\n",
    "precision_bernoulli_hh = precision_score(y_test_hh_spam, y_pred_bernoulli_hh, pos_label='spam')\n",
    "recall_bernoulli_hh = recall_score(y_test_hh_spam, y_pred_bernoulli_hh, pos_label='spam')\n",
    "\n",
    "# Generate confusion matrices\n",
    "conf_matrix_multinomial_hh = confusion_matrix(y_test_hh_spam, y_pred_multinomial_hh, labels=['spam', 'hard_ham'])\n",
    "conf_matrix_bernoulli_hh = confusion_matrix(y_test_hh_spam, y_pred_bernoulli_hh, labels=['spam', 'hard_ham'])\n",
    "\n",
    "# Plot and save confusion matrices without legends and with marginal sums\n",
    "plot_confusion_matrix_with_margins(conf_matrix_multinomial_hh, 'MultinomialNB_HardHam')\n",
    "plot_confusion_matrix_with_margins(conf_matrix_bernoulli_hh, 'BernoulliNB_HardHam')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Multinomial Naive Bayes (Hard Ham):\")\n",
    "print(f\"Accuracy: {accuracy_multinomial_hh:.4f}\")\n",
    "print(f\"Precision: {precision_multinomial_hh:.4f}\")\n",
    "print(f\"Recall: {recall_multinomial_hh:.4f}\\n\")\n",
    "\n",
    "print(\"Bernoulli Naive Bayes (Hard Ham):\")\n",
    "print(f\"Accuracy: {accuracy_bernoulli_hh:.4f}\")\n",
    "print(f\"Precision: {precision_bernoulli_hh:.4f}\")\n",
    "print(f\"Recall: {recall_bernoulli_hh:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification performance of the Multinomial Naive Bayes (MNB) and Bernoulli Naive Bayes (BNB) classifiers reveals distinct strengths in distinguishing between spam and the two types of ham emails. For Easy Ham vs. Spam, MNB achieved a high accuracy of 96.24% and an impressive precision of 98.75%, indicating that most emails it flagged as spam were indeed spam. However, its recall was moderate at 78.22%, suggesting that some spam emails were missed. In contrast, BNB maintained a similar high precision of 97.67% but suffered from a significantly lower recall of 41.58%, making it less effective in identifying all spam instances.\n",
    "\n",
    "When evaluating Hard Ham vs. Spam, MNB demonstrated exceptional performance with an accuracy of 97.35%, precision of 96.19%, and perfect recall of 100%, successfully identifying all spam emails without any false negatives. BNB also performed well in this scenario, achieving a high recall of 98.02% and a respectable precision of 88.39%, though slightly lower than MNB.\n",
    "\n",
    "These results indicate that MNB is generally more reliable across both ham types, offering a better balance between precision and recall. BNB, while maintaining high precision, may miss more spam emails in easier scenarios but improves significantly with harder-to-distinguish ham emails. Overall, Multinomial Naive Bayes proves to be the more robust classifier for spam detection in both Easy Ham and Hard Ham contexts, making it the preferred choice for comprehensive email classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro-ds-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
